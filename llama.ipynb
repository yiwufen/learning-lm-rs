{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd28471-764a-4383-a415-f53e8fee1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d8ac37",
   "metadata": {},
   "source": [
    "加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a16f093-f372-4930-a4d5-2c3ee98f0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型路径\n",
    "model_dir = \"models/story/\"\n",
    "\n",
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccd4c4",
   "metadata": {},
   "source": [
    "### 创建输入数据\n",
    "使用分词器将文本转化为模型的输入形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfb05f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor([[   1,   80,    0,   38,  232,  125, 2028,  158,   54,    0]])\n"
     ]
    }
   ],
   "source": [
    "input_text = \"这是一个测试句子。你可以利用Matplotlib或其他工具来可视化注意力权重等中间结果，帮助进一步理解模型的行为\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "print(input_ids.shape)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc01e7a",
   "metadata": {},
   "source": [
    "### 启用调试模式并逐层检查\n",
    "通过torch.no_grad()确保模型在推理模式下运行，并且不会计算梯度。你可以通过注册hook来提取模型各层的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51d2aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储中间层的输出\n",
    "outputs = {}\n",
    "\n",
    "def hook_fn_forward(module, input, output):\n",
    "    outputs[module] = output\n",
    "\n",
    "# 注册hook\n",
    "for name, module in model.model.named_modules():\n",
    "    module.register_forward_hook(hook_fn_forward)\n",
    "\n",
    "# 运行模型\n",
    "with torch.no_grad():\n",
    "    model(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c5e3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Embedding(2048, 128)\n",
      "tensor([[[-0.3125, -0.3164,  0.0684,  0.0454,  0.3262, -0.4590,  0.0251,\n",
      "           0.4062, -0.2852,  0.9102, -0.1973,  0.0327, -0.0247,  0.2002,\n",
      "           0.2197,  0.4961, -0.1001, -0.1719,  0.1543, -0.4180,  0.1953,\n",
      "           0.5273, -0.5938,  0.1768, -0.3125, -0.0417,  0.0518, -0.5000,\n",
      "           0.0309, -0.2695, -0.0491,  0.0649, -0.4492,  0.1885,  0.2559,\n",
      "           1.0078,  0.0527, -0.3457, -0.1562, -0.3906, -0.3262, -0.1836,\n",
      "          -0.1387,  0.1904,  0.1504, -0.3594,  0.2773, -0.1484,  0.1367,\n",
      "          -0.0811,  0.8906, -0.3047,  0.0679, -0.0791, -0.1934, -0.0605,\n",
      "          -0.0369,  0.1748, -0.3418, -0.3047, -0.4922, -0.2129,  0.1631,\n",
      "           0.0405,  0.2715, -0.2148, -0.0923,  0.4121,  0.1309,  0.0693,\n",
      "           0.0610, -0.0150,  0.3242,  0.8516,  0.0942, -0.1523, -0.0605,\n",
      "          -0.6797,  0.1787, -0.0046,  0.3047, -0.2988,  0.0525, -0.1982,\n",
      "          -0.0099, -0.4746, -0.4844, -0.1533,  0.0062,  3.2812,  2.2500,\n",
      "           0.0366, -0.2578,  0.2578, -0.0255,  0.2158,  0.1846, -0.2500,\n",
      "           0.0938, -0.2314, -0.0806, -0.3105,  0.0415,  0.2988, -0.0270,\n",
      "          -0.2930,  0.1875,  0.1226, -0.2578, -0.3770, -0.2656,  0.1201,\n",
      "           0.3359,  0.2256,  0.4375, -0.1953,  0.6328,  0.0820,  0.1582,\n",
      "           1.0156,  0.3320, -0.5859,  0.4219,  0.7461, -0.0070,  0.1943,\n",
      "          -0.3125, -0.1592],\n",
      "         [-0.1235,  0.5156,  0.5742,  0.5859,  0.2383,  0.1006, -1.2812,\n",
      "           0.0767, -0.1670, -0.3027, -0.3145,  0.3945, -0.4883, -0.8789,\n",
      "          -0.3770,  0.0284,  0.3906,  0.3594,  0.0918, -0.4434, -0.2158,\n",
      "          -0.4355,  0.1025,  0.4688,  0.5547, -0.2471, -0.9766, -0.4043,\n",
      "          -0.1953, -0.2246,  0.8672,  0.7148,  0.0703,  0.1143, -0.4570,\n",
      "           0.0559, -0.5117,  0.6602, -1.0547, -0.3867, -0.4531, -0.3047,\n",
      "          -0.2637,  0.6484, -0.1904,  0.4023, -0.4102,  0.2656,  0.2275,\n",
      "          -0.0713,  0.4902, -0.0718, -0.4707,  0.4492,  0.4473,  0.3066,\n",
      "           0.6836, -0.2500, -0.3223,  0.0427,  1.2500,  0.0226, -0.5664,\n",
      "           0.5586,  0.8008,  0.9531,  0.4766, -0.5039, -1.3594, -0.6094,\n",
      "          -0.3750, -0.4766,  0.4277,  0.2432, -0.0457,  0.6133, -0.1553,\n",
      "           0.4824,  0.1206,  0.1543,  0.1504, -0.1001, -0.1079, -0.3223,\n",
      "          -0.5195,  0.4355, -0.0292, -0.4512,  0.7656,  0.8008,  0.4512,\n",
      "          -0.0267,  0.3828, -0.1504, -0.1768, -0.7461,  0.0422, -0.3262,\n",
      "          -0.8594, -0.9570,  1.2656, -0.0288,  0.7305,  0.2021,  0.1445,\n",
      "           0.1641,  0.1299, -1.2109, -1.1406,  0.5938,  0.2148,  1.5469,\n",
      "           0.0049, -0.4434,  0.1621,  0.1221, -0.8906, -0.1143,  0.6641,\n",
      "           0.2314, -0.5195, -1.0156, -0.6484, -0.6992,  0.3691,  0.0698,\n",
      "           0.3066,  0.0245],\n",
      "         [-0.6836, -0.0259,  0.5898, -0.1689,  0.3477,  0.8203,  0.6445,\n",
      "          -0.5391, -0.0898,  0.5430,  0.4766, -0.6797,  0.2168, -0.2676,\n",
      "          -0.3477,  0.6094,  0.8047, -0.2871,  0.4062, -0.6328,  0.2305,\n",
      "          -0.2188, -0.2852, -0.4395,  0.5312,  0.3320,  0.2314, -0.0304,\n",
      "          -0.9648,  0.3223,  0.6523,  0.2393,  0.8242,  1.0625,  0.2539,\n",
      "          -0.0781,  0.0044, -0.1494, -0.4785, -0.1797,  0.3145, -0.3750,\n",
      "          -0.6484,  1.0156,  0.2715, -0.2344, -0.1021,  0.4375,  0.4180,\n",
      "          -0.2041,  0.1445,  0.0148,  0.2305,  0.5547,  0.0342,  0.2109,\n",
      "          -0.1475, -1.1094, -0.5078,  0.3477,  0.7969, -0.3848,  0.3320,\n",
      "          -0.2891,  0.2197,  0.4180,  0.0058,  0.4824, -0.0952, -0.6992,\n",
      "           0.2969, -0.7617, -0.3574, -0.7891, -0.2773, -0.8008,  0.7109,\n",
      "           0.2500, -0.5547,  0.5352,  0.6094, -0.1187,  0.0052,  0.9062,\n",
      "          -0.4473, -0.4668,  0.3926, -0.0569, -0.9219,  1.2500,  0.3125,\n",
      "          -0.0376, -0.4844, -0.1934,  0.3457,  0.1836, -0.0334,  0.0469,\n",
      "          -1.0156,  0.1436, -0.3359,  0.0317, -0.2227,  0.0659,  0.2031,\n",
      "           0.1943,  0.4863, -1.0547,  0.1943, -0.5117, -0.2061,  0.3438,\n",
      "           0.2188,  0.1191, -0.0684, -0.5547,  0.7734,  0.6914, -0.3789,\n",
      "           0.7109, -0.1030, -0.4277,  0.8477,  0.3418, -0.5195,  0.2139,\n",
      "           0.9414,  0.6211]]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 打印每一层的输出\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLayer: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(f\"Output shape: {output.shape()}\")\u001b[39;49;00m\n",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 打印每一层的输出\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLayer: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(f\"Output shape: {output.shape()}\")\u001b[39;49;00m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\dev_env\\lang_env\\python\\miniconda\\envs\\SNNs\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32md:\\dev_env\\lang_env\\python\\miniconda\\envs\\SNNs\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 打印每一层的输出\n",
    "for layer, output in outputs.items():\n",
    "    print(f\"Layer: {layer}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNNs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
